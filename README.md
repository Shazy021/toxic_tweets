# Классификация токсичных комментариев
<h1>Содержание<span class="tocSkip"></span></h1>
<ul class="toc-item"><li><span><a href="#1.-Подготовка" data-toc-modified-id="1.-Подготовка-1.1">1. Подготовка</a></span></li><li><span><a href="#2.-Первичный-анализ" data-toc-modified-id="2.-Первичный-анализ-1.2">2. Первичный анализ</a></span><ul class="toc-item"><li><span><a href="#Вывод" data-toc-modified-id="Вывод-1.2.1">Вывод</a></span></li></ul></li><li><span><a href="#3.-Обучение" data-toc-modified-id="3.-Обучение-1.3">3. Обучение</a></span></li><li><span><a href="#Выводы" data-toc-modified-id="Выводы-1.4">Выводы</a></span></li></ul></li></ul></div>


## Описание проекта
Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. 

Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. Обучим модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок.

## Описание данных

- text - содержит текст комментария
- toxic - целевой признак

## Вывод
Необходимая модель найдена, скор полученный на тестовой выборке удовлетворяет условию, в данных не найдены пропуски и дубликаты. Лучшая модель основана на алгоритме `LGBMClassifier(TFIDF)`
Полученный скор: $0.776479$
