{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<ul class=\"toc-item\"><li><span><a href=\"#1.-Подготовка\" data-toc-modified-id=\"1.-Подготовка-1.1\">1. Подготовка</a></span></li><li><span><a href=\"#2.-Первичный-анализ\" data-toc-modified-id=\"2.-Первичный-анализ-1.2\">2. Первичный анализ</a></span><ul class=\"toc-item\"><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-1.2.1\">Вывод</a></span></li></ul><li><span><a href=\"#3.-Обучение\" data-toc-modified-id=\"3.-Обучение-1.3\">3. Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-1.4\">Выводы</a></span></li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для интернет-магазина"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from lightgbm import LGBMClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "RND = 2102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_check(df):\n",
    "    \"\"\" Ф-ция first look на фрейм \"\"\"\n",
    "    print(df.info())\n",
    "    display(df)\n",
    "    display(df['toxic'].value_counts())\n",
    "    \n",
    "    all_comments = df['toxic'].value_counts()[0] + df['toxic'].value_counts()[1]\n",
    "    toxic_comments = df['toxic'].value_counts()[1]\n",
    "    \n",
    "    sns.barplot(x=[0,1], y=df['toxic'].value_counts())\n",
    "    plt.title(\"toxic hist\")\n",
    "    plt.xlabel(\"не токсичный/токсичный\")\n",
    "    plt.ylabel(\"Кол-во\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Токсичных комментариев: {round(toxic_comments/all_comments * 100, 2)}%\")\n",
    "    print(f\"Количество дубликатов: {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(text):\n",
    "        \"\"\" Обработка текста с помощью регулярных выражений \"\"\"\n",
    "        text = re.sub(r\"what's\", \"what is \", text)\n",
    "        text = re.sub(r\"\\'s\", \" \", text)\n",
    "        text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "        text = re.sub(r\"can't\", \"cannot \", text)\n",
    "        text = re.sub(r\"n't\", \" not \", text)\n",
    "        text = re.sub(r\"i'm\", \"i am \", text)\n",
    "        text = re.sub(r\"\\'re\", \" are \", text)\n",
    "        text = re.sub(r\"\\'d\", \" would \", text)\n",
    "        text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "        text = re.sub('\\W', ' ', text)\n",
    "        text = re.sub('\\s+', ' ', text)\n",
    "        text = text.strip(' ')\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class toxic_classification():\n",
    "    \"\"\"\n",
    "    Класс реализующий все этапы предобработки и классификацию комментариев (токсичный/не токсичный)\n",
    "    \"\"\"\n",
    "    def __init__(self, start_df,\n",
    "                 data_column,\n",
    "                 target_column,\n",
    "                 stop_words,\n",
    "                 score: str,\n",
    "                 models_whith_params,\n",
    "                 text_clearing=False):\n",
    "        \"\"\" Инициализация параметров \"\"\"\n",
    "        self.start_df = start_df\n",
    "        self.data_column = data_column\n",
    "        self.target_column = target_column\n",
    "        self.stop_words = stop_words\n",
    "        self.score = score\n",
    "        self.models_whith_params = models_whith_params\n",
    "        self.text_clearing = text_clearing\n",
    "        self.max_score = -1\n",
    "    \n",
    "        # preprocessing\n",
    "        print('---- Подготовка корпуса (1/3) ----')\n",
    "        self.pre_time = time.time()\n",
    "        self.start_time = time.time()\n",
    "        self.__corpus_preparation()\n",
    "        self.total_time = time.time() - self.start_time\n",
    "        print(f\"Первый этап пройден за {round(self.total_time, 2)} сек.\\n\")\n",
    "        \n",
    "        print('---- Лемматизации корпуса (2/3) ----')\n",
    "        self.start_time = time.time()\n",
    "        self.__lemmatisation()\n",
    "        self.total_time = time.time() - self.start_time\n",
    "        print(f\"Второй этап пройден за {round(self.total_time, 2)} сек.\\n\")\n",
    "        \n",
    "        print('---- Разбиение на train/test (3/3) ----')\n",
    "        self.start_time = time.time()\n",
    "        self.__tt_splitter()\n",
    "        self.total_time = time.time() - self.start_time\n",
    "        print(f\"Третий этап пройден за {round(self.total_time, 2)} сек.\\n\")\n",
    "        \n",
    "        self.all_time = time.time() - self.pre_time\n",
    "        print(f\"Общее время {self.all_time}\")\n",
    "        \n",
    "        del self.pre_time, self.start_time, self.total_time, self.all_time\n",
    "        \n",
    "\n",
    "    def __corpus_preparation(self):\n",
    "        \"\"\" Ф-ция подготовки корпуса \"\"\"\n",
    "        # Выделение корпуса\n",
    "        corpus = self.start_df[self.data_column].str.lower()\n",
    "        # Очистка корпуса от лишних символов\n",
    "        match self.text_clearing:\n",
    "            case True:\n",
    "                self.corpus = corpus.apply(lambda sentence: text_processing(sentence))\n",
    "                self.corpus = self.corpus.apply(lambda sentence: re.sub(r'[^a-z]',' ', sentence))\n",
    "            case _:\n",
    "                self.corpus = corpus.apply(lambda sentence: re.sub(r'[^a-z]',' ', sentence))\n",
    "            \n",
    "\n",
    "    def __lemmatisation(self):\n",
    "        \"\"\" Ф-ция по лемматизации слов корпуса \"\"\"\n",
    "        wnl = WordNetLemmatizer()\n",
    "        # Лемматизация корпуса\n",
    "        self.lemm_corpus = self.corpus.apply(lambda sentence: \" \".join([wnl.lemmatize(w,\"n\") for w in nltk.word_tokenize(sentence)]))\n",
    "        \n",
    "        \n",
    "    def __tt_splitter(self):\n",
    "        \"\"\" Ф-ция разбиения на train/test \"\"\"\n",
    "        self.split_df = train_test_split(self.lemm_corpus,\n",
    "                                         self.start_df[self.target_column],\n",
    "                                         test_size = 0.2, random_state=RND)\n",
    "        \n",
    "        self.splited_data = {\n",
    "            \"train\": {\n",
    "                \"features\": self.split_df[0],\n",
    "                \"target\": self.split_df[2],\n",
    "            },\n",
    "            \"test\": {\n",
    "                \"features\": self.split_df[1],\n",
    "                \"target\": self.split_df[3],\n",
    "            },\n",
    "            \n",
    "        }\n",
    "\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\" \n",
    "            Ф-ция тренировки переданных моделей \n",
    "        Буду использовать словарь black_box для хранения информации.\n",
    "        \n",
    "        Структура хранения в словаре black_box:\n",
    "        black_box[Имя модели][Информация по модели]\n",
    "        \n",
    "        Под информацией модели подразумеваю:\n",
    "        1) \"grid_object\"\n",
    "        2) \"best_model\"\n",
    "        3) \"best_score_train\"\n",
    "        4) \"best_score_test\"\n",
    "        5) \"train_time\"\n",
    "        6) \"predict_time\"\n",
    "        \"\"\"\n",
    "        # Инициализация словаря\n",
    "        self.black_box = {str(name):{} for name, _, _ in self.models_whith_params}\n",
    "        # Перебор моделей с параметрами\n",
    "        for model, params, model_name in tqdm(self.models_whith_params):\n",
    "            # Инициализация/тренировка грид серча\n",
    "            self.black_box[str(model)][\"grid_object\"] = GridSearchCV(model, params, cv=3, n_jobs=-1, scoring=self.score)\n",
    "            self.start_time = time.time()\n",
    "            self.black_box[str(model)][\"grid_object\"].fit(\n",
    "                self.splited_data['train']['features'],\n",
    "                self.splited_data['train']['target'],\n",
    "            )\n",
    "            self.train_time = time.time() - self.start_time\n",
    "            self.black_box[str(model)][\"train_time\"] = self.train_time\n",
    "            # Сохранение лучшей модели\n",
    "            self.black_box[str(model)][\"best_model\"] = self.black_box[str(model)][\"grid_object\"].best_estimator_\n",
    "            # Сохранение скоров\n",
    "            self.black_box[str(model)][\"best_score_train\"] = self.black_box[str(model)][\"grid_object\"].best_score_\n",
    "            self.start_time = time.time()\n",
    "            self.black_box[str(model)][\"best_score_test\"] = f1_score(self.splited_data['test']['target'], self.black_box[str(model)][\"best_model\"].predict(self.splited_data['test']['features']))\n",
    "            self.predict_time = time.time() - self.start_time\n",
    "            self.black_box[str(model)][\"pred_time\"] = self.predict_time\n",
    "\n",
    "            # Сохранение лучшей модели\n",
    "            if self.max_score < self.black_box[str(model)][\"best_score_test\"]:\n",
    "                self.max_score = self.black_box[str(model)][\"best_score_test\"]\n",
    "                self.best_model = self.black_box[str(model)][\"best_model\"]\n",
    "                self.best_model_score = (self.black_box[str(model)][\"best_score_train\"], self.black_box[str(model)][\"best_score_test\"])\n",
    "                self.best_model_time = (self.train_time, self.predict_time)\n",
    "            \n",
    "            del self.start_time, self.train_time, self.predict_time\n",
    "            \n",
    "        return {\"best_scores\": self.best_model_score, \"best_model\": self.best_model, \"time\": self.best_model_time}\n",
    "        \n",
    "        \n",
    "    def get_black_box(self):\n",
    "        \"\"\" Ф-ция возвращает всю собранную информацию об обучении \"\"\"\n",
    "        black_box = self.black_box\n",
    "        return black_box\n",
    "\n",
    "        \n",
    "    def report(self):\n",
    "        \"\"\" Ф-ци для создания таблицы с результатами\"\"\"\n",
    "        col = []\n",
    "        best_score_train = []\n",
    "        best_score_test = []\n",
    "        train_time = []\n",
    "        pred_time = []\n",
    "        \n",
    "        for model, params, model_name in self.models_whith_params:\n",
    "            col.append(model_name)\n",
    "            best_score_train.append(self.black_box[str(model)][\"best_score_train\"])\n",
    "            best_score_test.append(self.black_box[str(model)][\"best_score_test\"])\n",
    "            train_time.append(self.black_box[str(model)][\"train_time\"])\n",
    "            pred_time.append(self.black_box[str(model)][\"pred_time\"])\n",
    "            \n",
    "        report = pd.DataFrame(\n",
    "            columns = col,\n",
    "            index = [\n",
    "                'best_score_train',\n",
    "                'best_score_test',\n",
    "                'train_time',\n",
    "                'pred_time',\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        report.iloc[0] = best_score_train\n",
    "        report.iloc[1] = best_score_test\n",
    "        report.iloc[2] = train_time\n",
    "        report.iloc[3] = pred_time\n",
    "        \n",
    "        return report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Первичный анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth1 = '/datasets/toxic_comments.csv'\n",
    "pth2 = './data/toxic_comments.csv'\n",
    "\n",
    "if os.path.exists(pth1):\n",
    "    df = pd.read_csv(pth1)\n",
    "elif os.path.exists(pth2):\n",
    "    df = pd.read_csv(pth2)\n",
    "else:\n",
    "    print('Something is wrong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       Explanation\\nWhy the edits made under my usern...      0\n",
       "1       D'aww! He matches this background colour I'm s...      0\n",
       "2       Hey man, I'm really not trying to edit war. It...      0\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4       You, sir, are my hero. Any chance you remember...      0\n",
       "...                                                   ...    ...\n",
       "159566  \":::::And for the second time of asking, when ...      0\n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159569  And it looks like it was actually you who put ...      0\n",
       "159570  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159571 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Токсичных комментариев: 10.17%\n",
      "Количество дубликатов: 0\n"
     ]
    }
   ],
   "source": [
    "first_check(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 159571 строка;\n",
    "* Дубликатов и пропусков нет;\n",
    "* 2 столбца: `text`(features), `toxic`(target); \n",
    "* В столбце `text` содержатся тексты твитов;\n",
    "* В столбе `toxic` булевые значения является ли данный твит токсичным или нет;\n",
    "* 90% твитов не токсичны."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация пайплайнов\n",
    "pipe_lr_TFIDF = Pipeline(\n",
    "    [('vect', TfidfVectorizer(stop_words = stop_words, dtype=np.float32)),\n",
    "     ('clf', LogisticRegression(random_state=RND, class_weight='balanced', n_jobs=-1)),]\n",
    ")\n",
    "pipe_lr_CV = Pipeline(\n",
    "    [('vect', CountVectorizer(stop_words = stop_words, dtype=np.float32)),\n",
    "     ('clf', LogisticRegression(random_state=RND, class_weight='balanced', n_jobs=-1)),]\n",
    ")\n",
    "\n",
    "\n",
    "pipe_rf_TFIDF = Pipeline(\n",
    "    [('vect', TfidfVectorizer(stop_words = stop_words, dtype=np.float32)),\n",
    "     ('model', RandomForestClassifier(random_state=RND, class_weight='balanced', n_jobs=-1)),]\n",
    ")\n",
    "pipe_rf_CV = Pipeline(\n",
    "    [('vect', CountVectorizer(stop_words = stop_words, dtype=np.float32)),\n",
    "     ('model', RandomForestClassifier(random_state=RND, class_weight='balanced', n_jobs=-1)),]\n",
    ")\n",
    "\n",
    "\n",
    "pipe_lgbm_TFIDF = Pipeline(\n",
    "    [('vect', TfidfVectorizer(stop_words = stop_words, dtype=np.float32)),\n",
    "     ('model', LGBMClassifier(random_state=RND, n_jobs=-1)),]\n",
    ")\n",
    "pipe_lgbm_CV = Pipeline(\n",
    "    [('vect', CountVectorizer(stop_words = stop_words, dtype=np.float32)),\n",
    "     ('model', LGBMClassifier(random_state=RND, n_jobs=-1))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация параметров\n",
    "grid_params_lr ={\n",
    "    \"clf__max_iter\": [1000],\n",
    "    \"clf__C\": [0.5, 1, 10],\n",
    "}\n",
    "\n",
    "grid_params_rf = {\n",
    "    \"model__n_estimators\": [40, 80],\n",
    "    \"model__max_depth\": [2, 10],\n",
    "}\n",
    "\n",
    "grid_params_lgbm = {\n",
    "    \"model__n_estimators\": [200],\n",
    "    'model__learning_rate': [0.25, 0.4, 0.55],\n",
    "    'model__max_depth': [-1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Подготовка корпуса (1/3) ----\n",
      "Первый этап пройден за 15.08 сек.\n",
      "\n",
      "---- Лемматизации корпуса (2/3) ----\n",
      "Второй этап пройден за 90.85 сек.\n",
      "\n",
      "---- Разбиение на train/test (3/3) ----\n",
      "Третий этап пройден за 0.04 сек.\n",
      "\n",
      "Общее время 105.96525764465332\n",
      "CPU times: total: 1min 45s\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Инициализация класса\n",
    "cl = toxic_classification(\n",
    "    df,\n",
    "    'text',\n",
    "    'toxic',\n",
    "    stop_words,\n",
    "    'f1',\n",
    "    [(pipe_lr_TFIDF, grid_params_lr, \"LogisticRegression(TFIDF)\"),\n",
    "     (pipe_lr_CV, grid_params_lr, \"LogisticRegression(CountVect)\"),\n",
    "     (pipe_rf_TFIDF, grid_params_rf, \"RandomForestClassifier(TFIDF)\"),\n",
    "     (pipe_rf_CV, grid_params_rf, \"RandomForestClassifier(CountVect)\"),\n",
    "     (pipe_lgbm_TFIDF, grid_params_lgbm, \"LGBMClassifier(TFIDF)\"),\n",
    "     (pipe_lgbm_CV, grid_params_lgbm, \"LGBMClassifier(CountVect)\"),],\n",
    "    text_clearing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [08:42<00:00, 87.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 16min 5s\n",
      "Wall time: 8min 42s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_scores': (0.7700835554722718, 0.7764787995114291),\n",
       " 'best_model': Pipeline(steps=[('vect',\n",
       "                  TfidfVectorizer(dtype=<class 'numpy.float32'>,\n",
       "                                  stop_words=['i', 'me', 'my', 'myself', 'we',\n",
       "                                              'our', 'ours', 'ourselves', 'you',\n",
       "                                              \"you're\", \"you've\", \"you'll\",\n",
       "                                              \"you'd\", 'your', 'yours',\n",
       "                                              'yourself', 'yourselves', 'he',\n",
       "                                              'him', 'his', 'himself', 'she',\n",
       "                                              \"she's\", 'her', 'hers', 'herself',\n",
       "                                              'it', \"it's\", 'its', 'itself', ...])),\n",
       "                 ('model',\n",
       "                  LGBMClassifier(learning_rate=0.25, n_estimators=200,\n",
       "                                 random_state=2102))]),\n",
       " 'time': (206.27367615699768, 2.1373634338378906)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "best_model = cl.fit()\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Для анализа данных и построения модели предоставлен датасет с размеченными данными, содержащий комментарии пользователей к товарам, доступным для приобретения в интернет-магазине. Датасет состоит из 2 столбцов с данными и 159571 строкой;\n",
    "* Проверка соотношения классов показала, что в датасете имеет место явный дисбаланс;\n",
    "* В качестве моделей использованы `LogisticRegression`, `RandomForestClassifier` и `LGBMClassifier`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegression(TFIDF)</th>\n",
       "      <th>LogisticRegression(CountVect)</th>\n",
       "      <th>RandomForestClassifier(TFIDF)</th>\n",
       "      <th>RandomForestClassifier(CountVect)</th>\n",
       "      <th>LGBMClassifier(TFIDF)</th>\n",
       "      <th>LGBMClassifier(CountVect)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>best_score_train</th>\n",
       "      <td>0.760862</td>\n",
       "      <td>0.755888</td>\n",
       "      <td>0.362593</td>\n",
       "      <td>0.350868</td>\n",
       "      <td>0.770084</td>\n",
       "      <td>0.765841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_score_test</th>\n",
       "      <td>0.758229</td>\n",
       "      <td>0.757515</td>\n",
       "      <td>0.352618</td>\n",
       "      <td>0.345198</td>\n",
       "      <td>0.776479</td>\n",
       "      <td>0.77337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_time</th>\n",
       "      <td>55.668713</td>\n",
       "      <td>135.146905</td>\n",
       "      <td>24.684095</td>\n",
       "      <td>24.323995</td>\n",
       "      <td>206.273676</td>\n",
       "      <td>63.480782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_time</th>\n",
       "      <td>1.843055</td>\n",
       "      <td>2.061003</td>\n",
       "      <td>2.029255</td>\n",
       "      <td>1.939591</td>\n",
       "      <td>2.137363</td>\n",
       "      <td>2.091913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 LogisticRegression(TFIDF) LogisticRegression(CountVect)  \\\n",
       "best_score_train                  0.760862                      0.755888   \n",
       "best_score_test                   0.758229                      0.757515   \n",
       "train_time                       55.668713                    135.146905   \n",
       "pred_time                         1.843055                      2.061003   \n",
       "\n",
       "                 RandomForestClassifier(TFIDF)  \\\n",
       "best_score_train                      0.362593   \n",
       "best_score_test                       0.352618   \n",
       "train_time                           24.684095   \n",
       "pred_time                             2.029255   \n",
       "\n",
       "                 RandomForestClassifier(CountVect) LGBMClassifier(TFIDF)  \\\n",
       "best_score_train                          0.350868              0.770084   \n",
       "best_score_test                           0.345198              0.776479   \n",
       "train_time                               24.323995            206.273676   \n",
       "pred_time                                 1.939591              2.137363   \n",
       "\n",
       "                 LGBMClassifier(CountVect)  \n",
       "best_score_train                  0.765841  \n",
       "best_score_test                    0.77337  \n",
       "train_time                       63.480782  \n",
       "pred_time                         2.091913  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rep = cl.report()\n",
    "display(rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `LogisticRegression(TFIDF)`, `LogisticRegression(CountVect)`, `LGBMClassifier(TFIDF)` и `LGBMClassifier(CountVect)` успешно преодалели порог в 0.75 на тесте (по Т.З.);\n",
    "* В зависимости от пожеланий заказчика сможем ему предложить подходящую модель:\n",
    "    * Если заказчика не волнует время обучения модели, а интересует только скор на тестовой выборке, то сможем ему предложить `LGBMClassifier(TFIDF)`;\n",
    "    * Если заказчику понадобится самая быстрая модель, но с меньшей точностью предсказания, то предложим `LogisticRegression(TFIDF)`;\n",
    "    * Если понадобится модель с хорошей скоростью и скором, то сможем предложить `LGBMClassifier(CountVect)`.\n",
    "* На мой взгляд лучшей моделью будет `LGBMClassifier(CountVect)`, так мы сможем помочь заказчику сэкономть время и вычислителную мощность."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1179,
    "start_time": "2022-07-23T07:35:07.675Z"
   },
   {
    "duration": 80,
    "start_time": "2022-07-23T07:57:19.278Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "278px",
    "width": "260px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
